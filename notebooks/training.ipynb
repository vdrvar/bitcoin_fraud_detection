{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch\n",
    "    from torch_geometric.data import Data\n",
    "    import networkx as nx\n",
    "\n",
    "    # Function to convert data to PyTorch Geometric format\n",
    "    def create_pyg_data(features_df, classes_df, edgelist_df):\n",
    "        # Create a directed graph\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        # Add nodes with features and labels\n",
    "        for _, row in features_df.iterrows():\n",
    "            tx_id = row['txId']\n",
    "            features = row[1:].tolist()\n",
    "            tx_class = classes_df.loc[classes_df['txId'] == tx_id, 'class'].values[0]\n",
    "            G.add_node(tx_id, features=features, label=tx_class)\n",
    "\n",
    "        # Add edges\n",
    "        for _, row in edgelist_df.iterrows():\n",
    "            G.add_edge(row['txId1'], row['txId2'])\n",
    "\n",
    "        # Convert to PyTorch Geometric data format\n",
    "        edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "        x = torch.tensor([G.nodes[node]['features'] for node in G.nodes], dtype=torch.float)\n",
    "        y = torch.tensor([G.nodes[node]['label'] for node in G.nodes], dtype=torch.long)\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        return data\n",
    "\n",
    "    # Load the split datasets\n",
    "    X_train = pd.read_csv('../data/split/training_features.csv')\n",
    "    y_train = pd.read_csv('../data/split/training_labels.csv')\n",
    "    X_test = pd.read_csv('../data/split/test_features.csv')\n",
    "    y_test = pd.read_csv('../data/split/test_labels.csv')\n",
    "\n",
    "    # Merge features and labels for train and test datasets\n",
    "    train_data = create_pyg_data(X_train, y_train, edgelist_df)\n",
    "    test_data = create_pyg_data(X_test, y_test, edgelist_df)\n",
    "\n",
    "    print(train_data)\n",
    "    print(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define the GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model\n",
    "num_features = train_data.num_node_features\n",
    "num_classes = len(set(train_data.y.numpy()))\n",
    "model = GCN(num_features, num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training function\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, train_data, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred == data.y\n",
    "    acc = int(correct.sum()) / correct.size(0)\n",
    "    return acc\n",
    "\n",
    "# Testing the model\n",
    "train_acc = test(model, train_data)\n",
    "test_acc = test(model, test_data)\n",
    "print(f'Train Accuracy: {train_acc:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitcoin_fraud_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
